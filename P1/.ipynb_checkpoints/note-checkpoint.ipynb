{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "在正态分布中，mode = mean = median \n",
    "### 众数（mode）\n",
    "### 平均数（mean）\n",
    "### 中位数（median）\n",
    "- 奇数（odd）：$$ \\frac{X_{n+1}}{2} $$\n",
    "- 偶数（even）：$$ \\frac{X_{\\frac {n}{2}} + X_{\\frac{n}{2}+1}}{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQR（interquartile range）\n",
    "四分位数的间距IQR = Q3 - Q1\n",
    "\n",
    "分位线 | 值\n",
    "--- | ---\n",
    "   | 38946\n",
    "   | 43420\n",
    " Q1 | 49191\n",
    "   | 50430\n",
    "   | 50557\n",
    "   | 52580\n",
    "   | 53595\n",
    " Q3 | 54135\n",
    "   | 60181\n",
    "   | 100000          \n",
    "   \n",
    "缺点：完全不同的两个数据集可以有相同的IQR\n",
    "\n",
    "\n",
    "### 异常值outlier\n",
    "outlier的定义：outlier < Q1 - 1.5(IQR) 或 outlier > Q3 + 1.5(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 衡量数据差异性的方法\n",
    "平均偏差：计算均值与每个数据值之间的差值，再求这些差值的均值。\n",
    "缺点：未考虑负值\n",
    "$$ \\frac {\\sum(x_i - {\\bar x})}{10} $$\n",
    "\n",
    "绝对偏差\n",
    "$$ \\frac { \\sum|x_i - {\\bar x}| }{10} $$\n",
    "\n",
    "方差(variance) = 平均平方偏差(mean of squared deviations)\n",
    "$$ \\frac { \\sum(x_i - {\\bar x})^2 }{n} $$\n",
    "\n",
    "标准差SD（standard deviation）\n",
    "\n",
    "$$ \\sqrt \\frac { \\sum(x_i - {\\bar x})^2 }{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝塞尔校正系数（Bessel's correction）\n",
    "在计算样本的标准差时使用这个公式，n-1会使分母变小，导致最终样本的标准差偏大，这样才会使样本标准差**更接近于**总体标准差\n",
    "$$ \\sqrt \\frac { \\sum(x_i - {\\bar x})^2 }{ n-1 } $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "3.5\n",
      "1.70782512766\n"
     ]
    }
   ],
   "source": [
    "'''numpy计算均值，中位数，标准差'''\n",
    "import numpy as np\n",
    "\n",
    "num = [1, 2, 3, 4, 5, 6]\n",
    "print np.median(num)\n",
    "print np.mean(num)\n",
    "print np.std(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]]\n",
      "\n",
      "5.0\n",
      "\n",
      "[ 4.  5.  6.]\n",
      "\n",
      "[ 3.  6.]\n"
     ]
    }
   ],
   "source": [
    "two_D_array = np.array([[1, 2, 3], [4, 5, 6]], float)\n",
    "print two_D_array\n",
    "print \"\"\n",
    "print two_D_array[1][1]\n",
    "print \"\"\n",
    "print two_D_array[1, :]\n",
    "print \"\"\n",
    "print two_D_array[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''numpy.dot()计算每个国家的奖牌得分'''\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "def numpy_dot():\n",
    "    countries = ['Russian Fed.', 'Norway', 'Canada', 'United States',\n",
    "                 'Netherlands', 'Germany', 'Switzerland', 'Belarus',\n",
    "                 'Austria', 'France', 'Poland', 'China', 'Korea', \n",
    "                 'Sweden', 'Czech Republic', 'Slovenia', 'Japan',\n",
    "                 'Finland', 'Great Britain', 'Ukraine', 'Slovakia',\n",
    "                 'Italy', 'Latvia', 'Australia', 'Croatia', 'Kazakhstan']\n",
    "\n",
    "    gold = [13, 11, 10, 9, 8, 8, 6, 5, 4, 4, 4, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "    silver = [11, 5, 10, 7, 7, 6, 3, 0, 8, 4, 1, 4, 3, 7, 4, 2, 4, 3, 1, 0, 0, 2, 2, 2, 1, 0]\n",
    "    bronze = [9, 10, 5, 12, 9, 5, 2, 1, 5, 7, 1, 2, 2, 6, 2, 4, 3, 1, 2, 1, 0, 6, 2, 1, 0, 1]\n",
    " \n",
    "    # YOUR CODE HERE\n",
    "    olympic_medal_counts = {'country_name':Series(countries),\n",
    "                            'gold': Series(gold),\n",
    "                            'silver': Series(silver),\n",
    "                            'bronze': Series(bronze) }\n",
    "    df = DataFrame(olympic_medal_counts)\n",
    "    \n",
    "    medal_counts = df[['gold', 'silver', 'bronze']]\n",
    "    points = np.dot(medal_counts, [4,2,1])\n",
    "    temp = {'country_name': Series(countries), 'points':Series(points)}\n",
    "    olympic_points_df = DataFrame(temp)\n",
    "    return olympic_points_df\n",
    "\n",
    "#re = numpy_dot()\n",
    "#print re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses     int64\n",
      "team      object\n",
      "wins       int64\n",
      "year       int64\n",
      "dtype: object\n",
      "\n",
      "          losses       wins         year\n",
      "count   8.000000   8.000000     8.000000\n",
      "mean    6.625000   9.375000  2011.125000\n",
      "std     3.377975   3.377975     0.834523\n",
      "min     1.000000   4.000000  2010.000000\n",
      "25%     5.000000   7.500000  2010.750000\n",
      "50%     6.000000  10.000000  2011.000000\n",
      "75%     8.500000  11.000000  2012.000000\n",
      "max    12.000000  15.000000  2012.000000\n",
      "\n",
      "   losses     team  wins  year\n",
      "0       5    Bears    11  2010\n",
      "1       8    Bears     8  2011\n",
      "2       6    Bears    10  2012\n",
      "3       1  Packers    15  2011\n",
      "4       5  Packers    11  2012\n",
      "\n",
      "   losses     team  wins  year\n",
      "3       1  Packers    15  2011\n",
      "4       5  Packers    11  2012\n",
      "5      10    Lions     6  2010\n",
      "6       6    Lions    10  2011\n",
      "7      12    Lions     4  2012\n",
      "\n",
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "5    False\n",
      "6     True\n",
      "7    False\n",
      "Name: wins, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'year': [2010, 2011, 2012, 2011, 2012, 2010, 2011, 2012],\n",
    "        'team': ['Bears', 'Bears', 'Bears', 'Packers', 'Packers', 'Lions', 'Lions', 'Lions'],\n",
    "        'wins': [11, 8, 10, 15, 11, 6, 10, 4],\n",
    "        'losses': [5, 8, 6, 1, 5, 10, 6, 12]}\n",
    "football = pd.DataFrame(data)\n",
    "print football.dtypes\n",
    "print \"\"\n",
    "print football.describe()\n",
    "print \"\"\n",
    "print football.head()\n",
    "print \"\"\n",
    "print football.tail()\n",
    "print \"\"\n",
    "print football['wins'] > 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   losses     team  wins  year\n",
      "0       5    Bears    11  2010\n",
      "1       8    Bears     8  2011\n",
      "2       6    Bears    10  2012\n",
      "3       1  Packers    15  2011\n",
      "4       5  Packers    11  2012\n",
      "5      10    Lions     6  2010\n",
      "6       6    Lions    10  2011\n",
      "7      12    Lions     4  2012\n",
      "按行选取数据\n",
      "   losses   team  wins  year\n",
      "0       5  Bears    11  2010\n",
      "   losses   team  wins  year\n",
      "0       5  Bears    11  2010\n",
      "按列选取数据\n",
      "0      Bears\n",
      "1      Bears\n",
      "2      Bears\n",
      "3    Packers\n",
      "4    Packers\n",
      "5      Lions\n",
      "6      Lions\n",
      "7      Lions\n",
      "Name: team, dtype: object\n",
      "0      Bears\n",
      "1      Bears\n",
      "2      Bears\n",
      "3    Packers\n",
      "4    Packers\n",
      "5      Lions\n",
      "6      Lions\n",
      "7      Lions\n",
      "Name: team, dtype: object\n",
      "\n",
      "   losses     team  wins  year\n",
      "3       1  Packers    15  2011\n",
      "4       5  Packers    11  2012\n",
      "\n",
      "   losses     team  wins  year\n",
      "3       1  Packers    15  2011\n",
      "4       5  Packers    11  2012\n"
     ]
    }
   ],
   "source": [
    "data = {'year': [2010, 2011, 2012, 2011, 2012, 2010, 2011, 2012],\n",
    "            'team': ['Bears', 'Bears', 'Bears', 'Packers', 'Packers', 'Lions',\n",
    "                     'Lions', 'Lions'],\n",
    "            'wins': [11, 8, 10, 15, 11, 6, 10, 4],\n",
    "            'losses': [5, 8, 6, 1, 5, 10, 6, 12]}\n",
    "football = pd.DataFrame(data)\n",
    "print football\n",
    "print \"按行选取数据\"\n",
    "print football.iloc[[0]]\n",
    "print football.loc[[0]]\n",
    "print \"按列选取数据\"\n",
    "print football.team\n",
    "print football['team']\n",
    "print \"\"\n",
    "print football[3:5]\n",
    "print \"\"\n",
    "print football[(football.wins > 10) & (football.team == \"Packers\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "a  1.0    1\n",
      "b  2.0    2\n",
      "c  3.0    3\n",
      "d  NaN    4\n",
      "one    2.0\n",
      "two    2.5\n",
      "dtype: float64\n",
      "\n",
      "a    False\n",
      "b    False\n",
      "c     True\n",
      "d     True\n",
      "Name: two, dtype: bool\n",
      "\n",
      "     one    two\n",
      "a  False  False\n",
      "b  False  False\n",
      "c   True   True\n",
      "d  False   True\n"
     ]
    }
   ],
   "source": [
    "'''DataFrame.apply()'''\n",
    "d = {'one': Series([1, 2, 3], index = ['a', 'b', 'c']),\n",
    "     'two': Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])}\n",
    "df = DataFrame(d)\n",
    "print df\n",
    "print df.apply(np.mean)\n",
    "print \"\"\n",
    "print df['two'].map(lambda x: x>2)\n",
    "print \"\"\n",
    "print df.applymap(lambda x:x>2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''计算平均奖牌数'''\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "def create_dataframe():\n",
    "    countries = ['Russian Fed.', 'Norway', 'Canada', 'United States',\n",
    "                 'Netherlands', 'Germany', 'Switzerland', 'Belarus',\n",
    "                 'Austria', 'France', 'Poland', 'China', 'Korea', \n",
    "                 'Sweden', 'Czech Republic', 'Slovenia', 'Japan',\n",
    "                 'Finland', 'Great Britain', 'Ukraine', 'Slovakia',\n",
    "                 'Italy', 'Latvia', 'Australia', 'Croatia', 'Kazakhstan']\n",
    "\n",
    "    gold = [13, 11, 10, 9, 8, 8, 6, 5, 4, 4, 4, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "    silver = [11, 5, 10, 7, 7, 6, 3, 0, 8, 4, 1, 4, 3, 7, 4, 2, 4, 3, 1, 0, 0, 2, 2, 2, 1, 0]\n",
    "    bronze = [9, 10, 5, 12, 9, 5, 2, 1, 5, 7, 1, 2, 2, 6, 2, 4, 3, 1, 2, 1, 0, 6, 2, 1, 0, 1]\n",
    "\n",
    "    data = DataFrame({ 'countries':countries, 'gold':gold, 'silver':silver, 'bronze':bronze })\n",
    "    olympic_medal_counts_df = sum(data['gold']) / len(data['gold'])\n",
    "    return olympic_medal_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''计算金牌数大于等于1的国家的铜牌平均数'''\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "\n",
    "def avg_medal_count():\n",
    "    countries = ['Russian Fed.', 'Norway', 'Canada', 'United States',\n",
    "                 'Netherlands', 'Germany', 'Switzerland', 'Belarus',\n",
    "                 'Austria', 'France', 'Poland', 'China', 'Korea', \n",
    "                 'Sweden', 'Czech Republic', 'Slovenia', 'Japan',\n",
    "                 'Finland', 'Great Britain', 'Ukraine', 'Slovakia',\n",
    "                 'Italy', 'Latvia', 'Australia', 'Croatia', 'Kazakhstan']\n",
    "\n",
    "    gold = [13, 11, 10, 9, 8, 8, 6, 5, 4, 4, 4, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "    silver = [11, 5, 10, 7, 7, 6, 3, 0, 8, 4, 1, 4, 3, 7, 4, 2, 4, 3, 1, 0, 0, 2, 2, 2, 1, 0]\n",
    "    bronze = [9, 10, 5, 12, 9, 5, 2, 1, 5, 7, 1, 2, 2, 6, 2, 4, 3, 1, 2, 1, 0, 6, 2, 1, 0, 1]\n",
    "    \n",
    "    olympic_medal_counts = {'country_name':Series(countries),\n",
    "                            'gold': Series(gold),\n",
    "                            'silver': Series(silver),\n",
    "                            'bronze': Series(bronze)}\n",
    "    df = DataFrame(olympic_medal_counts)\n",
    "    \n",
    "    avg_bronze_at_least_one_gold = np.mean(df[df['gold'] >= 1]['bronze'])\n",
    "    return avg_bronze_at_least_one_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold      3.807692\n",
      "silver    3.730769\n",
      "bronze    3.807692\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''计算总奖牌数大于等于1的国家中，3种奖牌的平均值'''\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "def avg_medal_count():\n",
    "    countries = ['Russian Fed.', 'Norway', 'Canada', 'United States',\n",
    "                 'Netherlands', 'Germany', 'Switzerland', 'Belarus',\n",
    "                 'Austria', 'France', 'Poland', 'China', 'Korea', \n",
    "                 'Sweden', 'Czech Republic', 'Slovenia', 'Japan',\n",
    "                 'Finland', 'Great Britain', 'Ukraine', 'Slovakia',\n",
    "                 'Italy', 'Latvia', 'Australia', 'Croatia', 'Kazakhstan']\n",
    "\n",
    "    gold = [13, 11, 10, 9, 8, 8, 6, 5, 4, 4, 4, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "    silver = [11, 5, 10, 7, 7, 6, 3, 0, 8, 4, 1, 4, 3, 7, 4, 2, 4, 3, 1, 0, 0, 2, 2, 2, 1, 0]\n",
    "    bronze = [9, 10, 5, 12, 9, 5, 2, 1, 5, 7, 1, 2, 2, 6, 2, 4, 3, 1, 2, 1, 0, 6, 2, 1, 0, 1]\n",
    "    \n",
    "    olympic_medal_counts = {'country_name':countries,\n",
    "                            'gold': Series(gold),\n",
    "                            'silver': Series(silver),\n",
    "                            'bronze': Series(bronze)}    \n",
    "    df = DataFrame(olympic_medal_counts)\n",
    "\n",
    "    avg_medal_count = df[['gold', 'silver', 'bronze']].apply(np.mean)\n",
    "    \n",
    "    return avg_medal_count\n",
    "\n",
    "result = avg_medal_count()\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数值类型\n",
    "- 数值型\n",
    "- 分类型\n",
    "- 时间序列型\n",
    "\n",
    "把该类型数据当作分类或数值数据。建模的时候一定不能使用未来的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''对于类别型数据，标准做法是one-hot encoding，将类别转换为数字数据，在sklearn中有内建方法'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "X = X.select_dtypes(include=[object]) #选择类别型数据\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for feature in X:\n",
    "    X[feature] = le.fit_transform(X[feature])\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "xt = ohe.fit_transform(X)\n",
    "onehotlabels = xt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POI（person of interest）\n",
    "\n",
    "### 安然事件（Enron story）\n",
    "美国历史上最大的公司欺诈案例。下面记录wikipedia上纪录片[《Enron: The Smartest Guys in the Room》](https://en.wikipedia.org/wiki/Enron:_The_Smartest_Guys_in_the_Room)\n",
    "\n",
    "    Kenneth Lay在1985年成立了Enron。在公司成立2年后，由于公司的2名交易员开始在油价市场上投注，并获得了持续可疑的利润，导致公司陷入了丑闻。其中一名叫做Louis Borget的交易员也被发现转移公司资金到海外账户。在审计揭发了他们的行径以后，Lay反倒鼓励他们继续做下去能发大财。然而，这些交易员在被揭发赌光公司存款后就被炒掉了；总经理Mike Muckleroy通过对市场进行长期的虚张声势来弥补Borget造成的损失，避免追加保证金后公司才避免了破产的命运。在大量事实浮出水面后，Lay拒绝承认做错了事。\n",
    "    Lay雇佣了Jeffrey Skilling，后者是一个空想家，由于Enron公司使用市场计价法（在一些项目上当合同签订以后，不管交易产生的实际利润是多少，允许记录一些潜在的利润）而加入了Enron。这样即使在没赚什么钱的情况下，Enron公司也有能力表现出很有钱的样子。为了让Enron公司表现出从一个能源供应商到一个能源交易商的角色转换，Skilling对公司的发展布局进行了一番说明：建立一个评估委员会对员工进行评级，并每年解雇评分倒数15%的员工，这创造了一个高度竞争和残酷的工作环境。接着Skilling雇佣了那些在Enron内部执行他的指示的助手，被称为“钉刺人”。他们包括：Lou Pai，一个聪明但却很有抑郁的高管；J.Clifford Baxter，Enron能源服务公司的CEO，他因使用股东资金来满足他光顾脱衣舞俱乐部的习惯而臭名昭著。Pai在出售他的股票后不久就突然从他的2.5亿美元的股票中恢复了。尽管Pai已经赚了很多钱，但他之前的损失却损失了10亿美元，这是安然公司所掩盖的事实。Pai用他的钱在科罗拉多州买了一个大农场，成为了该州的第二大地主。\n",
    "    在互联网泡沫带来的牛市中，Enron公司的成功在于通过满足他们的预测来欺骗股票市场分析师。高管们推高了他们的股价，然后以数百万美元的期权变现，这一过程被称为“泵和抛售”。安然还发起了一场公关活动，将自己描绘成一家盈利、繁荣、创新的公司，尽管其在全球的业务表现不佳。在其他地方，安然开始了雄心勃勃的计划，比如试图利用宽带技术来满足需求：这两项举措都失败了。然而，通过按市值计价会计准则，安然公司记录了这些风险的利润。首席财务官Andrew Fastow创建了一个空壳公司的网络，目的是为了与安然公司做生意，因为这是为了向安然公司提供资金，并隐藏其不断增加的债务。Fastow还利用了华尔街投资银行的贪婪，迫使他们投资于这些空壳公司。然而，Fastow在这些风险投资中拥有既得利益，利用这些风险来欺骗安然公司的数千万美元的商业交易，而Fastow实际上是在与自己进行交易。所有这些都是在安然会计师事务所安达信和公司董事会的同意下完成的。这些交易中的大多数都与安然股票有关，这意味着安然股价的大幅下跌可能会导致Fastow的空壳公司网络崩溃。在此期间，安然的高管们鼓励该公司的员工将他们的储蓄和退休基金投资于安然股票，同时他们也在以数百万美元的价格出售他们的股票。\n",
    "    安然公司的成功仍在继续，因为它是2000年互联网泡沫破灭后为数不多的几家与互联网相关的公司之一，安然无恙，被财富杂志评为“最受尊敬”的公司，连续第六年被评为“最受尊敬的公司”。然而，安然公司的投资者Jim Chanos和财富杂志的记者Bethany McLean对公司的财务报表和股票价值提出了质疑。Skilling回应称，McLean的做法是“不道德的”，并指责财富杂志发表了她的报道，以抵消商业周刊对安然公司的正面报道。安然公司的三位高管与McLean和她的财富编辑会面，解释公司的财务状况。然而,安然公司的公众在加州能源危机时期发生了巨大的变化：由于能源危机，安然交易员利用国家摇摇欲坠的基础的新能源市场管制关闭发电厂和出口的国家权力创造人工短缺会抬高成本的电力安然的好处：安然将从此获得20亿美元。这部电影播放了安然交易员之间的录音对话，他们似乎从他们对危机的剥削中获得了乐趣，然后把Milgram的实验作为一种解释他们行为的方式。还探讨了强大的政治关系肯躺和安然,特别是政府的第41届总统乔治·h·w·布什和他的儿子,德克萨斯州州长,后来第43任总统乔治•布什(George w . Bush),表明安然加州能源危机期间的行动可能是有意的破坏加州州长戴维斯,被推测为一个强大的潜在挑战者布什在2004年总统大选。事实上，这场危机将间接导致戴维斯在2003年被召回，从而结束了他的政治生涯。Skilling当时是安然公司的首席执行官，他指责加州的能源法律是危机的原因，并否认安然的行为不当，在2001年的一场前线上，他说:“我们是好人，我们站在天使的一边。”尽管布什政府拒绝干预，但这部电影暗示可能是安然的影响，而反对派控制的参议院通过实施价格控制，结束了这场危机。布什与肯恩的关系受到了新闻媒体的密切关注，在安然倒闭后，新闻媒体的报道更为激烈。\n",
    "    与此同时，整个2001年，对Enron公司的资产负债表进行了更加严格的审查，并引起了首席执行官Skilling的不安。Skilling在公司及其欺诈行为开始瓦解之际，正处于神经崩溃的边缘。他从事奇怪的和非理性的行为——例如在一个电话会议上,当被问及为什么Enron并不像其竞争对手对其财政透明时，Skilling直言该投资者就是一个“混账”——在2001年8月，当Skilling突然辞去首席执行官且Lay取代他的位置后事件达到了高潮。Skilling的奇怪行为对投资者来说是一个危险的信号，他们开始质疑公司的财务健康状况，并开始出售他们的股票；随后安然的股价开始迅速下跌。Skilling离开后，Skilling刚刚在Enron公司的书中发现了欺诈行为，他警告说，除非他立即行动，否则该公司将走向崩溃。就像1987年一样，在很大程度上忽视了Skilling的警告，并向员工和公众保证，Skilling出于个人原因而离开了公司，而且公司在财务上是稳定的。与此同时，董事会在发现自己通过空壳公司盗用了超过3000万美元的资金后，迅速解雇了CFO。从1997年到2000年，Enron公司的会计问题的一系列报表消除大多数公司的利润,对公司的资产增加了近10亿美元的负债表,并删除超过10亿美元的股东权益的写下损失了Fastow的空壳公司。尽管安然公司继续保证安然状况良好，并将渡过难关，但由于投资者和客户都失去了信心，安然公司被迫在2001年11月申请破产保护。\n",
    "    由于安然的破产，许多员工失去了养老金和生活储蓄，而投资者损失了超过110亿美元的股东价值。国会听证会被纳入这一丑闻中，Kenneth Lay和Andrew Fastow为第五名辩护。Skilling最终在一项交易中认罪，他将为他的前同事作证，以换取他的刑期减少，而Lay和Fastow则无罪，并花费数千万美元在辩护律师上。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'salary': 1111258, 'to_messages': 3627, 'deferral_payments': 'NaN', 'total_payments': 8682716, 'exercised_stock_options': 19250000, 'bonus': 5600000, 'restricted_stock': 6843672, 'shared_receipt_with_poi': 2042, 'restricted_stock_deferred': 'NaN', 'total_stock_value': 26093672, 'expenses': 29336, 'loan_advances': 'NaN', 'from_messages': 108, 'other': 22122, 'from_this_person_to_poi': 30, 'poi': True, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 1920000, 'email_address': 'jeff.skilling@enron.com', 'from_poi_to_this_person': 88}\n"
     ]
    }
   ],
   "source": [
    "'''数据集中个人的数据类型'''\n",
    "import pickle\n",
    "enron_data = pickle.load(open(\"final_project_dataset.pkl\", \"r\"))\n",
    "print enron_data['SKILLING JEFFREY K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8682716\n",
      "103559793\n",
      "2424083\n"
     ]
    }
   ],
   "source": [
    "'''分别计算3个人获得的赃款'''\n",
    "import pickle\n",
    "enron_data = pickle.load(open(\"final_project_dataset.pkl\", \"r\"))\n",
    "\n",
    "print enron_data['SKILLING JEFFREY K']['total_payments']\n",
    "print enron_data['LAY KENNETH L']['total_payments']\n",
    "print enron_data['FASTOW ANDREW S']['total_payments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "'''计算数据集中有多少人的薪酬总额被设置了“NaN”？数据集中这些人的比例占多少？'''\n",
    "import pickle\n",
    "enron_data = pickle.load(open(\"D:/Code/ud120-projects-master/final_project/final_project_dataset.pkl\", \"r\"))\n",
    "\n",
    "count = 0\n",
    "for p in enron_data:\n",
    "    if isinstance(enron_data[p]['total_payments'], str):\n",
    "        count += 1\n",
    "\n",
    "print count\n",
    "print len(enron_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类指标\n",
    "- 准确率\n",
    "- 精确率\n",
    "- 召回率（查全率）\n",
    "- F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "'''准确率'''\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "print accuracy_score(y_true, y_pred)\n",
    "'''normalize默认为True，return正确样本所占的百分比'''\n",
    "print accuracy_score(y_true, y_pred, normalize=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text 精确率 = \\frac {TP}{TP + TN} = \\frac{\\text #预测正确的数量}{\\text #预测的结果数量} $$\n",
    "\n",
    "$$ \\text 召回率 = \\frac {TP}{TP + FP} = \\frac{\\text #预测正确的数量}{\\text #正确的样本数} $$\n",
    "\n",
    "F1可以理解为精确率和召回率的加权平均，最佳值为1，最差值为0\n",
    "$$ \\frac {2 * (\\text 精确率*召回率)}{\\text 精确率 + 召回率} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归指标\n",
    "- 平均绝对误差（MAE：mean absolute error）\n",
    "- 均方误差（MSE：mean square error）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "'''MAE：计算预测结果和真正结果数据之间的绝对误差，然后求和最后除以数据数量'''\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
    "y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
    "print mean_absolute_error(y_true, y_pred)\n",
    "# 绝对误差=4.5，共6个数据点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''MSE：残差（预测值与真实值的差值）被求平方，再除以数据数量'''\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2种回归分数函数\n",
    "- R2分数\n",
    "- 可释方差分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948608137045\n"
     ]
    }
   ],
   "source": [
    "'''R2'''\n",
    "from sklearn.metrics import r2_score\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "print r2_score(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957173447537\n"
     ]
    }
   ],
   "source": [
    "'''可释方差'''\n",
    "from sklearn.metrics import explained_variance_score\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "print explained_variance_score(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 误差的原因\n",
    "- 偏差（bias）:因模型无法表示基本数据的复杂度，造成欠拟合（underfitting）\n",
    "\n",
    "在训练集上存在很高的误差，意味着很低R^2值，很高的SSE（sum of squared error）\n",
    "- 方差（variance）:因模型对训练它所用的有限数据过度敏感，造成过拟合（overfitting）\n",
    "\n",
    "在训练集上有很高的拟合度，在测试集上训练结果不佳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this exercise we'll examine a learner which has high variance, and tries to learn nonexistant patterns in the data.\n",
    "# Use the learning curve function from sklearn.learning_curve to plot learning curves of both training and testing error.\n",
    "# CODE YOU HAVE TO TYPE IN IS IN LINE 35\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import learning_curve \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import explained_variance_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Set the learning curve parameters; you'll need this for learning_curves\n",
    "size = 1000\n",
    "cv = KFold(size,shuffle=True)\n",
    "score = make_scorer(explained_variance_score)\n",
    "\n",
    "# Create a series of data that forces a learner to have high variance\n",
    "X = np.round(np.reshape(np.random.normal(scale=5,size=2*size),(-1,2)),2)\n",
    "y = np.array([[np.sin(x[0] + np.sin(x[1]))] for x in X])\n",
    "\n",
    "def plot_curve():\n",
    "    reg = DecisionTreeRegressor()\n",
    "    reg.fit(X,y)\n",
    "    print \"Regressor score: {:.4f}\".format(reg.score(X,y))\n",
    "    \n",
    "    # TODO: Use learning_curve imported above to create learning curves for both the\n",
    "    #       training data and testing data. You'll need reg, X, y, cv and score from above.\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(reg, X, y, cv=cv, scoring=score)\n",
    "    \n",
    "    # Taking the mean of the test and training scores\n",
    "    train_scores_mean = np.mean(train_scores,axis=1)\n",
    "    test_scores_mean = np.mean(test_scores,axis=1)\n",
    "    \n",
    "    # Plotting the training curves and the testing curves using train_scores_mean and test_scores_mean \n",
    "    plt.plot(train_sizes ,train_scores_mean,'-o',color='b',label=\"train_scores_mean\")\n",
    "    plt.plot(train_sizes,test_scores_mean ,'-o',color='r',label=\"test_scores_mean\")\n",
    "    \n",
    "    # Plot aesthetics\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.ylabel(\"Curve Score\")\n",
    "    plt.xlabel(\"Training Points\")\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scott.fortmann-roe.com/docs/BiasVariance.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### K折交叉验证（K-fold cross validation）\n",
    "即进行K次单独的交叉验证试验。原理：将数据集划分成相同大小的两部分，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://discussions.youdaxue.com/t/grid-search/6079/2\n",
    "http://discussions.youdaxue.com/t/topic/13868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
